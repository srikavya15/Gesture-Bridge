Gesture Bridge

Speech-to-Sign Language Translator

Gesture Bridge is a speech-to-sign language translation application that converts live speech or recorded audio into Indian Sign Language (ISL) images or GIFs. The system is designed to reduce communication barriers between hearing individuals and the deaf or hard-of-hearing community by providing clear visual sign representations in real time.

**Features**

Captures live speech input through a microphone

Supports both online and offline speech recognition

Applies NLP-based text preprocessing for cleaner translations

Translates processed text into ISL using a dictionary-based approach

Displays corresponding ISL images or GIFs for better visual understanding

Includes a voice-controlled command to safely exit the application

**Tech Stack**

Programming Language: Python

GUI Framework: EasyGUI

Audio Input Handling: PyAudio

Speech Recognition Engines: Google Speech API, CMU Sphinx

Natural Language Processing: NLTK

Translation Method: Dictionary-based mapping to ISL signs

**Objective**

Enable accessible and inclusive communication using Indian Sign Language

Minimize dependency on human interpreters for basic conversations

Build a scalable architecture that can be extended to cover a wider ISL vocabulary

Lay the foundation for future deployment as a desktop or mobile application

 **Project Description**

Indian Sign Language is a visual and gesture-based language primarily used by individuals with hearing impairments. Since most hearing individuals are not trained in sign language, communication gaps frequently occur. Gesture Bridge addresses this problem by translating spoken language into corresponding ISL visuals, allowing users to communicate more effectively without requiring prior knowledge of sign language.

The application processes speech input, performs natural language preprocessing, and maps the processed text to appropriate ISL signs, which are then rendered visually to the user.
